# AI_Voice_Assistant

At the given state, this assistant is designed to listen to spoken commands or queries through a microphone, process these inputs using speech recognition and the OpenAI API (presumably for natural language understanding and generating responses), and then provide spoken feedback or answers using text-to-speech technology.

The goal is to be able to bridge other LLM's to be able to communicate via voice chat. (primarly those LLM's that are less known and dont have the same voice chat / GUI interface capabilities as OpenAI's ChatGPT)
